{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "def plot_line(slope, intercept):\n",
    "    axes = plt.gca()\n",
    "    x_vals = np.array(axes.get_xlim())\n",
    "    y_vals = intercept + slope * x_vals\n",
    "    plt.plot(x_vals, y_vals, '--')\n",
    "\n",
    "\n",
    "def set_axes_and_points(figure, X, y):\n",
    "    ax=figure.add_axes([0,0,1,1])\n",
    "    ax.scatter(X, y, color='b')\n",
    "    ax.set_xlabel('Free Lunches')\n",
    "    ax.set_ylabel('Happiness Level')\n",
    "    ax.set_title('Do Free Lunches cause Happiness?')\n",
    "    \n",
    "\n",
    "def plot_scatter_graph(X, y):\n",
    "    fig=plt.figure()\n",
    "    set_axes_and_points(fig, X, y)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_line_graph(X, y, slope, intercept):\n",
    "    fig_with_line=plt.figure()\n",
    "    set_axes_and_points(fig_with_line, X, y)\n",
    "    plot_line(slope,intercept)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d378a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ml_param_chart(names, params, title):\n",
    "    fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "    # creating the bar plot\n",
    "    plt.bar(names, params, color ='maroon', width = 0.4)\n",
    " \n",
    "    if len(names) > 4:\n",
    "        plt.xticks(rotation = 45)\n",
    "\n",
    "    plt.xlabel(\"ML Model\")\n",
    "    plt.ylabel(\"Number of Parameters\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "model_names = []\n",
    "num_params = []\n",
    "chart_titles = [\n",
    "    \"Size of our Model vs. RoBERTa base\",\n",
    "    \"Size of our Model vs. more RoBERTa models\", \n",
    "    \"Size of our Model vs. Foundation Models\",\n",
    "    \"Size of our Model vs. Foundation Models\",\n",
    "    \"Size of our Model vs. Foundation Models\",\n",
    "    \"Size of our Model vs. Foundation Models\"\n",
    "]\n",
    "\n",
    "data.append({'Our model (2)':2, 'RoBERTa base (125M)':125000000})\n",
    "data.append({'Our model (2)':2, 'RoBERTa base (125M)':125000000, 'RoBERTa large (355M)':355000000})\n",
    "data.append({'Our model (2)':2, 'RoBERTa base (125M)':125000000, 'RoBERTa large (355M)':355000000, \"DALL-E 2 (3.5B)\": 3500000000})\n",
    "data.append({'Our model (2)':2, 'RoBERTa base (125M)':125000000, 'RoBERTa large (355M)':355000000, \"DALL-E 2 (3.5B)\": 3500000000, \"GPT-3 (175B)\":175000000000})\n",
    "data.append({'Our model (2)':2, 'RoBERTa base (125M)':125000000, 'RoBERTa large (355M)':355000000, \"DALL-E 2 (3.5B)\": 3500000000, \"GPT-3 (175B)\":175000000000, \"PaLM (540B)\":540000000000})\n",
    "data.append({'Our model (2)':2, 'RoBERTa base (125M)':125000000, 'RoBERTa large (355M)':355000000, \"DALL-E 2 (3.5B)\": 3500000000, \"GPT-3 (175B)\":175000000000, \"PaLM (540B)\":540000000000, \"Wu Dao 2.0 (1.75T)\":1750000000000})\n",
    "\n",
    "for data_point in data:\n",
    "    model_names.append(list(data_point.keys()))\n",
    "    num_params.append(list(data_point.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-cruise",
   "metadata": {},
   "source": [
    "## Past observations about free lunches and happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_lunches    = [10, 20, 30, 40, 50, 60, 70,      90,  100]\n",
    "happiness_level = [18, 32, 40, 48, 66, 60, 83,      110, 109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_graph(free_lunches, happiness_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-instrument",
   "metadata": {},
   "source": [
    "## Audience Participation:  Guess the best ***slope*** and ***y-intercept***\n",
    "### Remember...\n",
    "###     ***slope*** is whether line goes upward/downward, and how \"steep\" it is\n",
    "###     ***y-intercept*** lets you move the line up/down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember... the model is the equation for a line:   y = slope_guess * x  + y_intercept_guess\n",
    "slope_guess = 0.9\n",
    "y_intercept_guess = 10\n",
    "\n",
    "plot_line_graph(free_lunches, happiness_level, slope_guess, y_intercept_guess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-driving",
   "metadata": {},
   "source": [
    "## Now we'll train an ML model to guess for us!!\n",
    "### (For the ML model, we've selected ordinary least squares Linear Regression.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "X = np.array(free_lunches).reshape((-1, 1))\n",
    "y = np.array(happiness_level)\n",
    "\n",
    "ml_model = reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-recommendation",
   "metadata": {},
   "source": [
    "## Which slope and y-intercept did the ML model learn based on the past observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_machine_learning_guess = ml_model.coef_[0]\n",
    "y_intercept_machine_learning_guess = ml_model.intercept_\n",
    "\n",
    "print(\"\\n\\n***************    The machine learned both parameters!!  :)\")\n",
    "print(\"***************        slope:       {}\".format(slope_machine_learning_guess))\n",
    "print(\"***************        y-intercept: {}\\n\\n\".format(y_intercept_machine_learning_guess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_line_graph(free_lunches, happiness_level, slope_machine_learning_guess, y_intercept_machine_learning_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_arr = np.array([80])\n",
    "predicted_happiness = ml_model.predict(value_arr.reshape(1, -1))[0]\n",
    "print(\"\\n\\n*** Our ML model predicts that 80 free lunches cause this much happiness: {}\\n\\n\".format(predicted_happiness))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "irish-absence",
   "metadata": {},
   "source": [
    "## Number of parameters learned by our newly-trained ML model:  _2_ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-mixture",
   "metadata": {},
   "source": [
    "## Number of parameters learned by the RoBERTa (base) natural language processing (NLP) model used by Capacity's IDP (mldocs-extractor): _125 million!!_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-polls",
   "metadata": {},
   "source": [
    "## (RoBERTa has \"read\" _all of Wikipedia_ and a _gigantic number of books_...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df971f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ml_param_chart(model_names[0], num_params[0], chart_titles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9240354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ml_param_chart(model_names[1], num_params[1], chart_titles[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927283ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ml_param_chart(model_names[2], num_params[2], chart_titles[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bc97a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ml_param_chart(model_names[3], num_params[3], chart_titles[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ml_param_chart(model_names[4], num_params[4], chart_titles[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72792410",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ml_param_chart(model_names[5], num_params[5], chart_titles[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c17c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
